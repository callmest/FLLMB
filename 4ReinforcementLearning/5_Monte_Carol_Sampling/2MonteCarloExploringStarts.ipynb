{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Exploring Starts\n",
    "\n",
    "è’™ç‰¹å¡æ´›Basicçš„ç®—æ³•çš„ç¼ºç‚¹æ˜¯éœ€è¦éå†æ¯ä¸€ä¸ª`state`çš„æ¯ä¸€ä¸ª`action`ï¼Œå¾—åˆ°`action value`\n",
    "\n",
    "ä½†åœ¨ç»è¿‡æ¯ä¸€ä¸ª`episode`çš„æ—¶å€™ï¼Œä¸­é—´ä¼šæœ‰å¾ˆå¤šé‡å¤çš„æ­¥éª¤ï¼Œç§°ä¹‹ä¸º`visit`ï¼Œæˆ–è®¸å¯ä»¥åªæ ¹æ®æˆ‘åœ¨ä¸€æ¡`episode`æ¢ç´¢çš„æ—¶å€™ï¼Œä¸­é—´è·å¾—çš„`visit`æ¥ä½œä¸ºå½“å‰çŠ¶æ€åŠ¨ä½œçš„`action value`\n",
    "\n",
    "å½“ç„¶è¿™æ ·æ˜¯ä¸ç²¾ç¡®çš„ï¼Œæ€ä¹ˆæ ·ç”¨`visit`æ¥åš`action value` ä¼šåœ¨ä¸‹ä¸€å°èŠ‚æåˆ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from GridWorld import GridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸\n",
      "â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸\n",
      "ğŸš«â¬œï¸â¬œï¸â¬œï¸â¬œï¸\n",
      "â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸\n",
      "ğŸš«âœ…â¬œï¸â¬œï¸ğŸš«\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9 \n",
    "rows = 5\n",
    "cols = 5\n",
    "# åŠ è½½ç½‘æ ¼ä¸–ç•Œ\n",
    "grid_world = GridWorld(rows, cols, forbiddenAreaReward= -10)\n",
    "grid_world.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¡ï¸â¬‡ï¸ğŸ”„â¬…ï¸â¬‡ï¸\n",
      "â¡ï¸ğŸ”„â¬†ï¸ğŸ”„ğŸ”„\n",
      "ğŸ”„ğŸ”„â¬…ï¸â¬…ï¸â¡ï¸\n",
      "â¬†ï¸â¬†ï¸â¬‡ï¸â¬†ï¸â¬†ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰episode length\n",
    "episode_length = 100\n",
    "\n",
    "# state value, åˆå§‹åŒ–ä¸º0ï¼Œ è¡¨ç¤ºæ¯ä¸ªstateçš„value\n",
    "value = np.zeros(rows*cols) \n",
    "# action value, åˆå§‹åŒ–ä¸º0, è¡¨ç¤ºæ¯ä¸ªstateçš„5ä¸ªactionçš„value\n",
    "qtable = np.zeros((rows*cols, 5)) \n",
    "\n",
    "# è’™ç‰¹å¡æ´›æ–¹æ³•ä¸€å¼€å§‹æ˜¯ä»ä¸€ä¸ªéšæœºçš„policyå¼€å§‹çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªéšæœºçš„policy\n",
    "# np.random.seed(50)\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*cols))] \n",
    "grid_world.show_policy_matirx(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Random Policy...\n",
      "done!\n",
      "Initial Q Table\n",
      "done!\n",
      "Start Q Value Update...\n",
      "q value update start at 0[125.0]\n",
      "now policy: \n",
      "â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â¬†ï¸â¬†ï¸â¬†ï¸â¬†ï¸\n",
      "â«ï¸â¬†ï¸â¬‡ï¸â¬†ï¸â¬†ï¸\n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "q value update end at : 0[168171.90793243307]\n",
      "q value update start at 1[168171.90793243307]\n",
      "now policy: \n",
      "â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â¬†ï¸â¬‡ï¸â¬†ï¸â¬†ï¸\n",
      "â¬â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "q value update end at : 1[167335.0540029216]\n",
      "q value update start at 2[167335.0540029216]\n",
      "now policy: \n",
      "â¡ï¸â¡ï¸â¬‡ï¸â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â©ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "q value update end at : 2[1198.494657015979]\n",
      "q value update start at 3[1198.494657015979]\n",
      "now policy: \n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â¬â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "q value update end at : 3[1310.7814712809559]\n",
      "q value update start at 4[1310.7814712809559]\n",
      "now policy: \n",
      "â¬‡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â©ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "q value update end at : 4[44.616643355203166]\n",
      "q value update start at 5[44.616643355203166]\n",
      "now policy: \n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â¬â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "q value update end at : 5[9.830201680304264e-08]\n",
      "Optimal Policy Found!\n",
      "Final Policy\n",
      "â¡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â¬â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
      "â¡ï¸â¬‡ï¸â¬…ï¸â¬…ï¸â¬…ï¸\n",
      "â©ï¸âœ…â¬…ï¸â¬…ï¸âª\n",
      "Final Q Table\n",
      "[[-4.09533905  6.56076095  6.56073439 -4.09533905  5.90466095]\n",
      " [-3.43923905  5.90466095  7.28963565  5.90466095  6.56076095]\n",
      " [-4.09533905  5.31417095  6.56076095  6.56067208  5.90466095]\n",
      " [-4.68582905  4.78272995  5.90466095  5.90460487  5.31417095]\n",
      " [-5.21727005 -5.21727005  5.31417095  5.31414439  4.78272995]\n",
      " [ 5.90466095  7.28973439 -2.71023905 -3.43923905  6.56076095]\n",
      " [ 6.56076095  6.56076095  8.09973439  6.56076095  7.28976095]\n",
      " [ 5.90466095  5.90466095  7.28973439  7.28976095  6.56076095]\n",
      " [ 5.31417095  5.31417095  6.56073439  6.56076095  5.90466095]\n",
      " [ 4.78272995 -4.68582905  5.90463439  5.90466095  5.31417095]\n",
      " [ 6.56076095  8.09973439  8.09976095 -2.71023905 -2.71023905]\n",
      " [ 7.28976095  7.28976095  8.99963565 -2.71023905  8.09976095]\n",
      " [ 6.56076095  6.56076095  8.09976095  8.09967208  7.28976095]\n",
      " [ 5.90466095  5.90466095  7.28976095  7.28970487  6.56076095]\n",
      " [ 5.31417095 -4.09533905  6.56076095  6.56073439  5.90466095]\n",
      " [-2.71023905  8.99973439 -1.00023905 -1.90023905  8.09976095]\n",
      " [ 8.09976095  8.09976095  9.99973439  8.09976095  8.99976095]\n",
      " [ 7.28976095  7.28976095  8.99973439  8.99976095  8.09976095]\n",
      " [ 6.56076095  6.56076095  8.09970487  8.09976095  7.28976095]\n",
      " [ 5.90466095 -3.43923905 -2.71023905  7.28973439  6.56076095]\n",
      " [ 8.09976095  9.99973439 -1.00023905 -1.00023905 -1.00023905]\n",
      " [ 8.99976095  8.99976095 -1.00023905 -1.00023905  9.15628416]\n",
      " [ 8.09976095  8.09976095 -1.00023905  9.99967208  8.99976095]\n",
      " [ 7.28976095 -2.71023905 -1.90023905  8.99970487  8.09976095]\n",
      " [ 6.56076095 -2.71023905 -2.71023905  8.09973439 -2.71023905]]\n"
     ]
    }
   ],
   "source": [
    "# é€šè¿‡é‡‡æ ·çš„æ–¹æ³•è®¡ç®—action value\n",
    "# è¿™é‡Œå’Œpolicy iterationä¸åŒçš„åœ°æ–¹æ˜¯ï¼Œåœ¨policy iterationä¸­ï¼Œæˆ‘ä»¬æ˜¯é€šè¿‡è¿­ä»£çš„æ–¹æ³•æ¥è®¡ç®—valueï¼Œè€Œåœ¨è’™ç‰¹å¡æ´›æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬æ˜¯é€šè¿‡é‡‡æ ·çš„æ–¹æ³•æ¥è®¡ç®—value\n",
    "# åœ¨policy iterationä¸­ï¼Œæˆ‘ä»¬æ˜¯å·²çŸ¥ä¸€ä¸ªå›ºå®šç­–ç•¥çš„\n",
    "\n",
    "print('Generate Random Policy...')\n",
    "qtable = np.zeros((rows*cols, 5))\n",
    "print('done!')\n",
    "print('Initial Q Table')\n",
    "pre_qtabel = qtable.copy() + 1\n",
    "print('done!')\n",
    "threshold = 0.001\n",
    "print('Start Q Value Update...')\n",
    "cut = 0\n",
    "cut_threshold = 1000\n",
    "while np.sum((pre_qtabel-qtable)**2) > threshold and cut < cut_threshold:\n",
    "    print('-----------------------------------')\n",
    "    print(f'q value update start at {cut}[{np.sum((pre_qtabel-qtable)**2)}]')\n",
    "    pre_qtabel = qtable.copy()\n",
    "    # é€šè¿‡é‡‡æ ·çš„æ–¹æ³•è®¡ç®—action value\n",
    "    # éå†æ¯ä¸€ä¸ªçŠ¶æ€\n",
    "    for i in range(rows*cols):\n",
    "        # éå†æ¯ä¸€ä¸ªaction\n",
    "        for j in range(5):\n",
    "            # åˆå§‹åŒ–qtable_rewardså’Œqtable_counts\n",
    "\n",
    "            qtable_rewards = [[0 for _ in range(5)] for _ in range(rows*cols)]\n",
    "            qtable_counts = [[0 for _ in range(5)] for _ in range(rows*cols)]\n",
    "            # ä¸‹é¢å‡½æ•°çš„è¿”å›å€¼æ˜¯ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ï¼Œæ¯ä¸€ä¸ªå…ƒç»„åŒ…å«ä¸€ä¸ªepisodeçš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬state, action, reward\n",
    "            episode = grid_world.get_episode_score(\n",
    "                now_state=i,\n",
    "                action=j,\n",
    "                policy=policy,\n",
    "                steps=episode_length,\n",
    "            )\n",
    "\n",
    "            reward = episode[episode_length][2]\n",
    "            for k in range(episode_length-1, -1, -1):\n",
    "                # éœ€è¦æå–å‡ºæ¯ä¸€ä¸ªepisodeçš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬state, action, reward\n",
    "                temp_state = episode[k][0]\n",
    "                temp_action = episode[k][1]\n",
    "                temp_reward = episode[k][2]\n",
    "                # å…ˆè®¡ç®—å½“å‰çš„action value\n",
    "                reward = temp_reward + gamma * reward\n",
    "                # æ›´æ–°qtable_rewardså’Œqtable_counts\n",
    "                # å°†episodeä¸­çš„rewardåŠ å…¥åˆ°qtable_rewardsä¸­\n",
    "                qtable_rewards[temp_state][temp_action] += reward\n",
    "                # å°†episodeä¸­çš„countåŠ å…¥åˆ°qtable_countsä¸­\n",
    "                qtable_counts[temp_state][temp_action] += 1  \n",
    "                # è¿™é‡Œé‡‡ç”¨çš„æ˜¯å¹³å‡å€¼çš„æ–¹æ³•æ¥æ›´æ–°qtableï¼Œ å³every visit\n",
    "                qtable[temp_state][temp_action] = qtable_rewards[temp_state][temp_action] / qtable_counts[temp_state][temp_action]\n",
    "\n",
    "                # first visit\n",
    "                # if qtable_counts[temp_state][temp_action] == 0:\n",
    "                #     qtable_rewards[temp_state][temp_action] = reward\n",
    "                #     qtable[temp_state][temp_action] = qtable_rewards[temp_state][temp_action] / qtable_counts[temp_state][temp_action]\n",
    "                #     qtable_counts[temp_state][temp_action] += 1 \n",
    "    \n",
    "    # é€‰å–æœ€å¤§çš„action valueçš„actionä½œä¸ºpolicy\n",
    "    policy = np.eye(5)[np.argmax(qtable, axis=1)]\n",
    "    print('now policy: ')\n",
    "    grid_world.show_policy_matirx(policy)\n",
    "    print(f'q value update end at : {cut}[{np.sum((pre_qtabel-qtable)**2)}]')\n",
    "    cut += 1\n",
    "    print('-----------------------------------')\n",
    "print('Optimal Policy Found!')\n",
    "print('Final Policy')\n",
    "grid_world.show_policy_matirx(policy)\n",
    "print('Final Q Table')\n",
    "print(qtable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBP-TSTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

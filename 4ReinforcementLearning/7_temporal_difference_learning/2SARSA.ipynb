{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 原理解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sarsa (state-action-reward-state-action) \n",
    "\n",
    "- 用来计算某一个状态下采取某一个动作的action value\n",
    "\n",
    "- 注意：当我们进行 policy evaluation 得到 action value 后， 立刻进行 policy update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 代码详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from GridWorld import GridWorld\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Grid World\n",
      "⬜️⬜️⬜️⬜️⬜️\n",
      "⬜️🚫🚫⬜️⬜️\n",
      "⬜️⬜️🚫⬜️⬜️\n",
      "⬜️🚫✅🚫⬜️\n",
      "⬜️🚫⬜️⬜️⬜️\n",
      "Initial Policy\n",
      "⬆️⬅️⬆️⬅️➡️\n",
      "⬇️⏪⏩️⬅️🔄\n",
      "⬇️⬇️⏫️⬆️⬆️\n",
      "🔄⏪✅⏬➡️\n",
      "⬅️⏬➡️⬅️🔄\n",
      "Initial State Value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Initial Action Value: [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "rows = 5\n",
    "columns = 5\n",
    "gridworld  = GridWorld(forbiddenAreaReward=-10, reward=1, desc=[\".....\", \".##..\", \"..#..\", \".#T#.\", \".#...\"])\n",
    "print('Initial Grid World')\n",
    "gridworld.show()\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "print('Initial Policy')\n",
    "gridworld.show_policy_matirx(policy)\n",
    "\n",
    "value = np.zeros((rows * columns))\n",
    "print(f'Initial State Value: {value}')\n",
    "\n",
    "action_value = np.zeros((rows * columns, 5))\n",
    "print(f'Initial Action Value: {action_value}')\n",
    "\n",
    "# Hyperparameters\n",
    "num_episodes = 1000\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 286 \\ 1000\n",
      "episode end, trajectory length: 14\n",
      "state value updated: \n",
      "[-6.11020297 -4.65421421 -4.3238123  -2.14133525 -2.67905476 -4.1471937\n",
      " -3.76379137 -1.04817291  0.44754809 -1.86193979 -3.34648771 -2.9077425\n",
      "  5.8558343   1.89208948  2.42288588 -3.47177349  5.71492079  5.64838663\n",
      "  5.58699491  3.03196797 -4.89566669  1.94418577  5.96934303  4.98459251\n",
      "  3.51467724]\n",
      "policy updated\n",
      "⬇️➡️⬅️⬇️🔄\n",
      "⬇️⏬⏩️⬇️⬅️\n",
      "➡️🔄⏬➡️⬇️\n",
      "⬆️⏩️✅⏪⬇️\n",
      "⬆️⏩️⬆️⬅️⬅️\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolicy updated\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m     gridworld\u001b[38;5;241m.\u001b[39mshow_policy_matirx(policy)\n\u001b[1;32m---> 48\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m gridworld\u001b[38;5;241m.\u001b[39mshow_policy_matirx(policy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in range(num_episodes):\n",
    "    clear_output(wait=True)\n",
    "    print(f'episode: {episode} \\ {num_episodes}')\n",
    "    # 定义epsilon-greedy策略\n",
    "    greedy_action_prob = 1 - epsilon * (4 / 5)\n",
    "    non_greedy_action_prob = epsilon / 5\n",
    "    action_dict = { 1: greedy_action_prob,\n",
    "                   0: non_greedy_action_prob}\n",
    "    # 这一步是根据epsilon-greedy策略赋予每个状态动作的概率\n",
    "    policy_epsilon_greedy = np.vectorize(action_dict.get)(policy)\n",
    "    # 检查每个状态被访问的次数\n",
    "    state_visited = [0 for _ in range(rows * columns)]\n",
    "    # 随机选取一个初始化状态和动作\n",
    "    init_state = random.choice(range(rows * columns))\n",
    "    init_action = random.choice(range(5))\n",
    "\n",
    "    # 获取一条轨迹,收集数据，规定达到终点才算一条轨迹\n",
    "    trajectory = gridworld.get_episode_score(now_state=init_state,\n",
    "                                             action=init_action,\n",
    "                                             policy=policy_epsilon_greedy,\n",
    "                                             steps=-1,\n",
    "                                             stop_when_reach_target=True)\n",
    "\n",
    "    print(f'episode end, trajectory length: {len(trajectory)}')\n",
    "    # 利用获取的action value更新policy\n",
    "    steps = len(trajectory) - 1\n",
    "    # 从后往前更新，减少计算量， 迭代式的求解方式\n",
    "    for k in range(steps, -1, -1):\n",
    "        last_state, last_action, reward, next_state, next_action = trajectory[k]\n",
    "        # print(f'last_state: {last_state}, last_action: {last_action}, reward: {reward}, next_state: {next_state}, next_action: {next_action}')\n",
    "        state_visited[last_state] += 1\n",
    "        # 应用SARSA，注意这里直接是next_action\n",
    "        TD_error = action_value[last_state][last_action] - (reward + gamma * action_value[next_state][next_action])\n",
    "        action_value[last_state][last_action] -= alpha * TD_error\n",
    "\n",
    "    # 更新policy 选取action value最大的动作作为policy\n",
    "    # 用argmax来索引最大值. 并且用np.eye(5)来生成one-hot编码，即最大值的位置为1，其余为0\n",
    "    policy = np.eye(5)[np.argmax(action_value, axis=1)]\n",
    "    policy_epsilon_greedy = np.vectorize(action_dict.get)(policy)\n",
    "    state_value = np.sum(action_value * policy_epsilon_greedy, axis=1)\n",
    "    mean_state_value = np.mean(state_value)\n",
    "    \n",
    "    print(f'state value updated: \\n{state_value}')\n",
    "    print('policy updated')\n",
    "    gridworld.show_policy_matirx(policy)\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "\n",
    "print('Final Policy')\n",
    "gridworld.show_policy_matirx(policy)\n",
    "print('Final State Value')\n",
    "print(state_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBP-TSTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

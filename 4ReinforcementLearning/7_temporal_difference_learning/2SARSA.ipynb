{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŸç†è§£é‡Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sarsa (state-action-reward-state-action) \n",
    "\n",
    "- ç”¨æ¥è®¡ç®—æŸä¸€ä¸ªçŠ¶æ€ä¸‹é‡‡å–æŸä¸€ä¸ªåŠ¨ä½œçš„action value\n",
    "\n",
    "- æ³¨æ„ï¼šå½“æˆ‘ä»¬è¿›è¡Œ policy evaluation å¾—åˆ° action value åï¼Œ ç«‹åˆ»è¿›è¡Œ policy update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ä»£ç è¯¦è§£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from GridWorld import GridWorld\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Grid World\n",
      "â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸\n",
      "â¬œï¸ğŸš«ğŸš«â¬œï¸â¬œï¸\n",
      "â¬œï¸â¬œï¸ğŸš«â¬œï¸â¬œï¸\n",
      "â¬œï¸ğŸš«âœ…ğŸš«â¬œï¸\n",
      "â¬œï¸ğŸš«â¬œï¸â¬œï¸â¬œï¸\n",
      "Initial Policy\n",
      "â¬†ï¸â¬…ï¸â¬†ï¸â¬…ï¸â¡ï¸\n",
      "â¬‡ï¸âªâ©ï¸â¬…ï¸ğŸ”„\n",
      "â¬‡ï¸â¬‡ï¸â«ï¸â¬†ï¸â¬†ï¸\n",
      "ğŸ”„âªâœ…â¬â¡ï¸\n",
      "â¬…ï¸â¬â¡ï¸â¬…ï¸ğŸ”„\n",
      "Initial State Value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Initial Action Value: [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "rows = 5\n",
    "columns = 5\n",
    "gridworld  = GridWorld(forbiddenAreaReward=-10, reward=1, desc=[\".....\", \".##..\", \"..#..\", \".#T#.\", \".#...\"])\n",
    "print('Initial Grid World')\n",
    "gridworld.show()\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "print('Initial Policy')\n",
    "gridworld.show_policy_matirx(policy)\n",
    "\n",
    "value = np.zeros((rows * columns))\n",
    "print(f'Initial State Value: {value}')\n",
    "\n",
    "action_value = np.zeros((rows * columns, 5))\n",
    "print(f'Initial Action Value: {action_value}')\n",
    "\n",
    "# Hyperparameters\n",
    "num_episodes = 1000\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 286 \\ 1000\n",
      "episode end, trajectory length: 14\n",
      "state value updated: \n",
      "[-6.11020297 -4.65421421 -4.3238123  -2.14133525 -2.67905476 -4.1471937\n",
      " -3.76379137 -1.04817291  0.44754809 -1.86193979 -3.34648771 -2.9077425\n",
      "  5.8558343   1.89208948  2.42288588 -3.47177349  5.71492079  5.64838663\n",
      "  5.58699491  3.03196797 -4.89566669  1.94418577  5.96934303  4.98459251\n",
      "  3.51467724]\n",
      "policy updated\n",
      "â¬‡ï¸â¡ï¸â¬…ï¸â¬‡ï¸ğŸ”„\n",
      "â¬‡ï¸â¬â©ï¸â¬‡ï¸â¬…ï¸\n",
      "â¡ï¸ğŸ”„â¬â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â©ï¸âœ…âªâ¬‡ï¸\n",
      "â¬†ï¸â©ï¸â¬†ï¸â¬…ï¸â¬…ï¸\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolicy updated\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m     gridworld\u001b[38;5;241m.\u001b[39mshow_policy_matirx(policy)\n\u001b[1;32m---> 48\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m gridworld\u001b[38;5;241m.\u001b[39mshow_policy_matirx(policy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in range(num_episodes):\n",
    "    clear_output(wait=True)\n",
    "    print(f'episode: {episode} \\ {num_episodes}')\n",
    "    # å®šä¹‰epsilon-greedyç­–ç•¥\n",
    "    greedy_action_prob = 1 - epsilon * (4 / 5)\n",
    "    non_greedy_action_prob = epsilon / 5\n",
    "    action_dict = { 1: greedy_action_prob,\n",
    "                   0: non_greedy_action_prob}\n",
    "    # è¿™ä¸€æ­¥æ˜¯æ ¹æ®epsilon-greedyç­–ç•¥èµ‹äºˆæ¯ä¸ªçŠ¶æ€åŠ¨ä½œçš„æ¦‚ç‡\n",
    "    policy_epsilon_greedy = np.vectorize(action_dict.get)(policy)\n",
    "    # æ£€æŸ¥æ¯ä¸ªçŠ¶æ€è¢«è®¿é—®çš„æ¬¡æ•°\n",
    "    state_visited = [0 for _ in range(rows * columns)]\n",
    "    # éšæœºé€‰å–ä¸€ä¸ªåˆå§‹åŒ–çŠ¶æ€å’ŒåŠ¨ä½œ\n",
    "    init_state = random.choice(range(rows * columns))\n",
    "    init_action = random.choice(range(5))\n",
    "\n",
    "    # è·å–ä¸€æ¡è½¨è¿¹,æ”¶é›†æ•°æ®ï¼Œè§„å®šè¾¾åˆ°ç»ˆç‚¹æ‰ç®—ä¸€æ¡è½¨è¿¹\n",
    "    trajectory = gridworld.get_episode_score(now_state=init_state,\n",
    "                                             action=init_action,\n",
    "                                             policy=policy_epsilon_greedy,\n",
    "                                             steps=-1,\n",
    "                                             stop_when_reach_target=True)\n",
    "\n",
    "    print(f'episode end, trajectory length: {len(trajectory)}')\n",
    "    # åˆ©ç”¨è·å–çš„action valueæ›´æ–°policy\n",
    "    steps = len(trajectory) - 1\n",
    "    # ä»åå¾€å‰æ›´æ–°ï¼Œå‡å°‘è®¡ç®—é‡ï¼Œ è¿­ä»£å¼çš„æ±‚è§£æ–¹å¼\n",
    "    for k in range(steps, -1, -1):\n",
    "        last_state, last_action, reward, next_state, next_action = trajectory[k]\n",
    "        # print(f'last_state: {last_state}, last_action: {last_action}, reward: {reward}, next_state: {next_state}, next_action: {next_action}')\n",
    "        state_visited[last_state] += 1\n",
    "        # åº”ç”¨SARSAï¼Œæ³¨æ„è¿™é‡Œç›´æ¥æ˜¯next_action\n",
    "        TD_error = action_value[last_state][last_action] - (reward + gamma * action_value[next_state][next_action])\n",
    "        action_value[last_state][last_action] -= alpha * TD_error\n",
    "\n",
    "    # æ›´æ–°policy é€‰å–action valueæœ€å¤§çš„åŠ¨ä½œä½œä¸ºpolicy\n",
    "    # ç”¨argmaxæ¥ç´¢å¼•æœ€å¤§å€¼. å¹¶ä¸”ç”¨np.eye(5)æ¥ç”Ÿæˆone-hotç¼–ç ï¼Œå³æœ€å¤§å€¼çš„ä½ç½®ä¸º1ï¼Œå…¶ä½™ä¸º0\n",
    "    policy = np.eye(5)[np.argmax(action_value, axis=1)]\n",
    "    policy_epsilon_greedy = np.vectorize(action_dict.get)(policy)\n",
    "    state_value = np.sum(action_value * policy_epsilon_greedy, axis=1)\n",
    "    mean_state_value = np.mean(state_value)\n",
    "    \n",
    "    print(f'state value updated: \\n{state_value}')\n",
    "    print('policy updated')\n",
    "    gridworld.show_policy_matirx(policy)\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "\n",
    "print('Final Policy')\n",
    "gridworld.show_policy_matirx(policy)\n",
    "print('Final State Value')\n",
    "print(state_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBP-TSTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

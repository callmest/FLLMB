{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŸç†è§£é‡Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qlearning ä¸ SARSA ä¸åŒçš„åœ°æ–¹åªåœ¨äº TD target, åœ¨ SARSA ä¸­, æˆ‘ä»¬ä¼šæ”¶é›† (now_state, now_action, reward, next_state, next_action) çš„æ•°æ®ï¼Œè¿™é‡Œçš„ next_action æ˜¯é€šè¿‡ random.choice é€‰å–å‡ºæ¥çš„ï¼Œä½†æ˜¯åœ¨ Qlearning ä¸­ï¼Œæ˜¯ç›´æ¥åˆ©ç”¨è´ªå¿ƒçš„ç­–ç•¥ï¼Œä¸éœ€è¦è¾“å…¥ next_action çš„æ•°æ®ï¼Œ è€Œæ˜¯åœ¨ç›´æ¥é€‰æ‹© next_state ä¸‹ï¼Œæ‰€æœ‰åŠ¨ä½œçš„ action_value çš„æœ€å¤§å€¼ã€‚\n",
    "\n",
    "åŒæ—¶éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒQlearning æœ¬èº«æ˜¯ä¸€ä¸ª off-policy çš„ç®—æ³•ï¼Œ å› ä¸º Qlearning çš„ç›®çš„æ˜¯æƒ³è¦å¾—åˆ° optimal policy , è¿™å’Œæˆ‘ä»¬ å½“å‰é‡‡å–çš„ policy æ˜¯ä¸åŒçš„ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. ä»£ç å®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 off policy (classical ver.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from GridWorld import GridWorld\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Grid World\n",
      "â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸\n",
      "â¬œï¸ğŸš«ğŸš«â¬œï¸â¬œï¸\n",
      "â¬œï¸â¬œï¸ğŸš«â¬œï¸â¬œï¸\n",
      "â¬œï¸ğŸš«âœ…ğŸš«â¬œï¸\n",
      "â¬œï¸ğŸš«â¬œï¸â¬œï¸â¬œï¸\n",
      "Initial Policy\n",
      "â¬…ï¸â¬‡ï¸ğŸ”„ğŸ”„â¡ï¸\n",
      "â¬…ï¸â©ï¸âªâ¡ï¸â¡ï¸\n",
      "â¬…ï¸â¬…ï¸ğŸ”„â¬‡ï¸â¬‡ï¸\n",
      "â¬…ï¸âªâœ…â«ï¸ğŸ”„\n",
      "â¡ï¸â«ï¸â¡ï¸â¡ï¸ğŸ”„\n",
      "Initial State Value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Initial Action Value: [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "rows = 5\n",
    "columns = 5\n",
    "\n",
    "gridworld  = GridWorld(forbiddenAreaReward=-10, reward=1, desc=[\".....\", \".##..\", \"..#..\", \".#T#.\", \".#...\"])\n",
    "print('Initial Grid World')\n",
    "gridworld.show()\n",
    "\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "print('Initial Policy')\n",
    "gridworld.show_policy_matirx(policy)\n",
    "\n",
    "state_value = np.zeros((rows * columns))\n",
    "print(f'Initial State Value: {state_value}')\n",
    "\n",
    "action_value = np.zeros((rows * columns, 5))\n",
    "print(f'Initial Action Value: {action_value}')\n",
    "\n",
    "# Hyperparameters\n",
    "num_episodes = 1000\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 999 \\ 1000\n",
      "episode end, trajectory length: 8\n",
      "state value updated: \n",
      "[1.82116797 2.02768054 2.25589071 2.50868309 2.78898621 1.6312208\n",
      " 1.60034826 1.89171341 1.95175734 3.10038853 1.44321933 1.06824428\n",
      " 4.8340822  2.81955038 3.44609244 1.13984092 4.86200633 4.73039236\n",
      " 4.89368464 3.83000398 0.65329565 4.4304419  5.2566311  4.73027429\n",
      " 4.2565327 ]\n",
      "policy updated\n",
      "â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â«ï¸â«ï¸â¬†ï¸â¬‡ï¸\n",
      "â¬†ï¸â¬…ï¸â¬â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â©ï¸âœ…âªâ¬‡ï¸\n",
      "â¬†ï¸â©ï¸â¬†ï¸â¬…ï¸â¬…ï¸\n",
      "Final Policy\n",
      "â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â«ï¸â«ï¸â¬†ï¸â¬‡ï¸\n",
      "â¬†ï¸â¬…ï¸â¬â¡ï¸â¬‡ï¸\n",
      "â¬†ï¸â©ï¸âœ…âªâ¬‡ï¸\n",
      "â¬†ï¸â©ï¸â¬†ï¸â¬…ï¸â¬…ï¸\n",
      "Final State Value\n",
      "[1.82116797 2.02768054 2.25589071 2.50868309 2.78898621 1.6312208\n",
      " 1.60034826 1.89171341 1.95175734 3.10038853 1.44321933 1.06824428\n",
      " 4.8340822  2.81955038 3.44609244 1.13984092 4.86200633 4.73039236\n",
      " 4.89368464 3.83000398 0.65329565 4.4304419  5.2566311  4.73027429\n",
      " 4.2565327 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in range(num_episodes):\n",
    "    clear_output(wait=True)\n",
    "    print(f'episode: {episode} \\ {num_episodes}')\n",
    "        # å®šä¹‰epsilon-greedyç­–ç•¥\n",
    "    # greedy_action_prob = 1 - epsilon * (4 / 5)\n",
    "    # non_greedy_action_prob = epsilon / 5\n",
    "    # action_dict = { 1: greedy_action_prob,\n",
    "    #                0: non_greedy_action_prob}\n",
    "    # # è¿™ä¸€æ­¥æ˜¯æ ¹æ®epsilon-greedyç­–ç•¥èµ‹äºˆæ¯ä¸ªçŠ¶æ€åŠ¨ä½œçš„æ¦‚ç‡\n",
    "    # policy_epsilon_greedy = np.vectorize(action_dict.get)(policy)\n",
    "    # æ£€æŸ¥æ¯ä¸ªçŠ¶æ€è¢«è®¿é—®çš„æ¬¡æ•°\n",
    "    state_visited = [0 for _ in range(rows * columns)]\n",
    "    # éšæœºé€‰å–ä¸€ä¸ªçŠ¶æ€å’ŒåŠ¨ä½œ, æ ¹æ®ä¹¦ä¸­off-policyçš„ä¼ªä»£ç ï¼Œä¸éœ€è¦epsilon-greedyç­–ç•¥\n",
    "    now_state = random.choice(range(rows * columns))\n",
    "    now_action = random.choice(range(5))\n",
    "\n",
    "    # æ ¹æ®ä¼ªä»£ç ï¼Œåœ¨ä¸€ä¸ª episode ä¸‹ï¼Œæˆ‘ä»¬æ ¹æ®å…ˆæœ‰çš„ç­–ç•¥ï¼Œç”Ÿæˆä¸€æ¡è½¨è¿¹ï¼Œè·å–æ•°æ®\n",
    "    trajectory = gridworld.get_episode_score(\n",
    "        now_state=now_state,\n",
    "        action=now_action,\n",
    "        policy=policy,\n",
    "        steps=-1,\n",
    "        stop_when_reach_target=True\n",
    "    )\n",
    "    print(f'episode end, trajectory length: {len(trajectory)}')\n",
    "\n",
    "    # ç°åœ¨éœ€è¦qlearningæ¥æ›´æ–°action_valueï¼Œæ³¨æ„è¿™é‡Œæ˜¯åå‘æ›´æ–°, éœ€è¦ç»™len(trajectory)å‡å»1ï¼Œå› ä¸ºlengthå¦‚æœæ˜¯1ï¼Œé‚£ä¹ˆä¼šå¾ªç¯2æ¬¡\n",
    "    for k in range(len(trajectory) - 1, -1, -1):\n",
    "        last_state, last_action, reward, next_state, next_action = trajectory[k]\n",
    "        state_visited[last_state] += 1\n",
    "        # qlearningçš„æ›´æ–°å…¬å¼: Q(s, a)(t+1) = Q(s, a)(t) - alpha * (Q(s, a)(t) - (r + gamma * max_a' Q(s, a)(t+1)))\n",
    "        # æ³¨æ„è¿™é‡Œæ˜¯é€‰æ‹©äº†ä¸‹ä¸€ä¸ªçŠ¶æ€çš„æœ€å¤§action value çš„åŠ¨ä½œï¼Œè€Œä¸æ˜¯next_action\n",
    "        TD_target = reward + gamma * np.max(action_value[next_state])\n",
    "        TD_error = action_value[last_state][last_action] - TD_target\n",
    "        # æ›´æ–°action_value\n",
    "        action_value[last_state][last_action] -= alpha * TD_error\n",
    "        # æ›´æ–°policy\n",
    "        policy[last_state] = np.eye(5)[np.argmax(action_value[last_state])]\n",
    "\n",
    "    # æ›´æ–°state value\n",
    "    state_value = np.max(action_value, axis=1)\n",
    "    print(f'state value updated: \\n{state_value}')\n",
    "    print('policy updated')\n",
    "    gridworld.show_policy_matirx(policy)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "print('Final Policy')\n",
    "gridworld.show_policy_matirx(policy)\n",
    "print('Final State Value')\n",
    "print(state_value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBP-TSTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

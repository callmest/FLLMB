{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 值迭代\n",
    "值迭代是解决贝尔曼最优公式的解法之一\n",
    "\n",
    "贝尔曼最优公式：\n",
    "$$ v^{*} = r_{\\pi}^{*} + \\gamma P_{\\pi}v^{*} $$\n",
    "\n",
    "贝尔曼最优公式， 根据`contracting theorem`可以通过迭代的方式求解：\n",
    "$$ v_{k+1} = f(v_k) = \\max_{\\pi}(r_{\\pi} + \\gamma P_{\\pi}v_{k}) $$\n",
    "\n",
    "我们可以通过两个步骤来求解这个方程式：\n",
    "\n",
    "第一步：策略更新\n",
    "\n",
    "可以随机的给出一个 $v_{k}$ 的值，然后解决一个优化问题：\n",
    "$$\n",
    "\\pi_{k+1} = \\argmax_{\\pi}(r_{\\pi} + \\gamma P_{\\pi}v_{k})\n",
    "$$\n",
    "即：\n",
    "$$\n",
    "\\pi_{k+1}(s) = \\argmax_{\\pi} \\sum_{a} \\pi(a|s) \\underbrace{(\\sum_{r}p(r|s,a)r + \\gamma \\sum_{s^{\\prime}}p(s^{\\prime}|s,a)v_{k}(s^{\\prime}))}_{q_\\pi(a, s)}, s \\in \\mathbb{S}\n",
    "$$\n",
    "代入初始的`state value`后，对于每一个状态s，根据策略的不同，我可以算出每个策略所对应的`action value`，此时的\n",
    "$\\pi_{k+1}$ 即是我求出最大`action value`时对应的策略。\n",
    "\n",
    "第二步：值更新\n",
    "\n",
    "再根据更新的策略代入上面的式子更新 `state value`\n",
    "$$\n",
    "v_{k+1} = r_{{\\pi}_{k+1}} + \\gamma P_{{\\pi}_{k+1}}v_{k}\n",
    "$$\n",
    "即：\n",
    "$$\n",
    "v_{k+1}(s) =  \\sum_{a} \\pi_{k+1}(a|s) \\underbrace{(\\sum_{r}p(r|s,a)r + \\gamma \\sum_{s^{\\prime}}p(s^{\\prime}|s,a)v_{k}(s^{\\prime}))}_{q_\\pi(a, s)}, s \\in \\mathbb{S}\n",
    "$$\n",
    "因为这里的 $\\pi_{k+1}$ 是贪心策略求出的，所以第二步的值实际上对应的就是采取 $\\pi_{k+1}$ 时的`action value`\n",
    "\n",
    "由于我们这里的 $v_{k}$ 是随机初始化的，所以它并不是一个真实的`state value`只有当 $k \\to \\infty$的时候才可以称为`state value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\callmest\\.conda\\envs\\RBP-TSTL\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from GridWorld import GridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬜️⬜️⬜️⬜️⬜️\n",
      "⬜️⬜️⬜️⬜️⬜️\n",
      "🚫⬜️⬜️⬜️⬜️\n",
      "⬜️⬜️⬜️⬜️⬜️\n",
      "🚫✅⬜️⬜️🚫\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9 # discount rate, 范围[0, 1)， 0表示只关心当前reward，1表示关心所有future reward\n",
    "rows = 5\n",
    "cols = 5\n",
    "# 加载网格世界\n",
    "grid_world = GridWorld(rows, cols)\n",
    "grid_world.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "初始policy: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "⬆️⬆️⬆️⬆️⬆️\n",
      "⬆️⬆️⬆️⬆️⬆️\n",
      "⏫️⬆️⬆️⬆️⬆️\n",
      "⬆️⬆️⬆️⬆️⬆️\n",
      "⏫️✅⬆️⬆️⏫️\n"
     ]
    }
   ],
   "source": [
    "value = np.zeros(rows*cols) # state value, 初始化为0， 表示每个state的value\n",
    "qtable = np.zeros((rows*cols, 5)) # action value, 初始化为0, 表示每个state的5个action的value\n",
    "policy = np.argmax(qtable, axis=1) # policy, 初始化为0，表示每个state的最优action, 这里的policy实际上是最优policy\n",
    "print(f'初始value: {value}')\n",
    "print(f'初始policy: {policy}')\n",
    "grid_world.show_policy_list(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬜️⬜️⬜️⬜️⬜️\n",
      "⬜️⬜️⬜️⬜️⬜️\n",
      "🚫⬜️⬜️⬜️⬜️\n",
      "⬜️⬜️⬜️⬜️⬜️\n",
      "🚫✅⬜️⬜️🚫\n",
      "➡️⬇️⬇️⬇️⬇️\n",
      "➡️⬇️⬇️⬇️⬇️\n",
      "⏩️⬇️⬇️⬇️⬇️\n",
      "➡️⬇️⬇️⬇️⬅️\n",
      "⏩️✅⬅️⬅️⏪\n",
      "Euclidean Distance: 25.0\n",
      "nowState: (0, 0), action: 0, nextState: (-1, 0)\n",
      "nowState: (0, 0), action: 1, nextState: (0, 1)\n",
      "nowState: (0, 0), action: 2, nextState: (1, 0)\n",
      "nowState: (0, 0), action: 3, nextState: (0, -1)\n",
      "nowState: (0, 0), action: 4, nextState: (0, 0)\n",
      "nowState: (0, 1), action: 0, nextState: (-1, 1)\n",
      "nowState: (0, 1), action: 1, nextState: (0, 2)\n",
      "nowState: (0, 1), action: 2, nextState: (1, 1)\n",
      "nowState: (0, 1), action: 3, nextState: (0, 0)\n",
      "nowState: (0, 1), action: 4, nextState: (0, 1)\n",
      "nowState: (0, 2), action: 0, nextState: (-1, 2)\n",
      "nowState: (0, 2), action: 1, nextState: (0, 3)\n",
      "nowState: (0, 2), action: 2, nextState: (1, 2)\n",
      "nowState: (0, 2), action: 3, nextState: (0, 1)\n",
      "nowState: (0, 2), action: 4, nextState: (0, 2)\n",
      "nowState: (0, 3), action: 0, nextState: (-1, 3)\n",
      "nowState: (0, 3), action: 1, nextState: (0, 4)\n",
      "nowState: (0, 3), action: 2, nextState: (1, 3)\n",
      "nowState: (0, 3), action: 3, nextState: (0, 2)\n",
      "nowState: (0, 3), action: 4, nextState: (0, 3)\n",
      "nowState: (0, 4), action: 0, nextState: (-1, 4)\n",
      "nowState: (0, 4), action: 1, nextState: (0, 5)\n",
      "nowState: (0, 4), action: 2, nextState: (1, 4)\n",
      "nowState: (0, 4), action: 3, nextState: (0, 3)\n",
      "nowState: (0, 4), action: 4, nextState: (0, 4)\n",
      "nowState: (1, 0), action: 0, nextState: (0, 0)\n",
      "nowState: (1, 0), action: 1, nextState: (1, 1)\n",
      "nowState: (1, 0), action: 2, nextState: (2, 0)\n",
      "nowState: (1, 0), action: 3, nextState: (1, -1)\n",
      "nowState: (1, 0), action: 4, nextState: (1, 0)\n",
      "nowState: (1, 1), action: 0, nextState: (0, 1)\n",
      "nowState: (1, 1), action: 1, nextState: (1, 2)\n",
      "nowState: (1, 1), action: 2, nextState: (2, 1)\n",
      "nowState: (1, 1), action: 3, nextState: (1, 0)\n",
      "nowState: (1, 1), action: 4, nextState: (1, 1)\n",
      "nowState: (1, 2), action: 0, nextState: (0, 2)\n",
      "nowState: (1, 2), action: 1, nextState: (1, 3)\n",
      "nowState: (1, 2), action: 2, nextState: (2, 2)\n",
      "nowState: (1, 2), action: 3, nextState: (1, 1)\n",
      "nowState: (1, 2), action: 4, nextState: (1, 2)\n",
      "nowState: (1, 3), action: 0, nextState: (0, 3)\n",
      "nowState: (1, 3), action: 1, nextState: (1, 4)\n",
      "nowState: (1, 3), action: 2, nextState: (2, 3)\n",
      "nowState: (1, 3), action: 3, nextState: (1, 2)\n",
      "nowState: (1, 3), action: 4, nextState: (1, 3)\n",
      "nowState: (1, 4), action: 0, nextState: (0, 4)\n",
      "nowState: (1, 4), action: 1, nextState: (1, 5)\n",
      "nowState: (1, 4), action: 2, nextState: (2, 4)\n",
      "nowState: (1, 4), action: 3, nextState: (1, 3)\n",
      "nowState: (1, 4), action: 4, nextState: (1, 4)\n",
      "nowState: (2, 0), action: 0, nextState: (1, 0)\n",
      "nowState: (2, 0), action: 1, nextState: (2, 1)\n",
      "nowState: (2, 0), action: 2, nextState: (3, 0)\n",
      "nowState: (2, 0), action: 3, nextState: (2, -1)\n",
      "nowState: (2, 0), action: 4, nextState: (2, 0)\n",
      "nowState: (2, 1), action: 0, nextState: (1, 1)\n",
      "nowState: (2, 1), action: 1, nextState: (2, 2)\n",
      "nowState: (2, 1), action: 2, nextState: (3, 1)\n",
      "nowState: (2, 1), action: 3, nextState: (2, 0)\n",
      "nowState: (2, 1), action: 4, nextState: (2, 1)\n",
      "nowState: (2, 2), action: 0, nextState: (1, 2)\n",
      "nowState: (2, 2), action: 1, nextState: (2, 3)\n",
      "nowState: (2, 2), action: 2, nextState: (3, 2)\n",
      "nowState: (2, 2), action: 3, nextState: (2, 1)\n",
      "nowState: (2, 2), action: 4, nextState: (2, 2)\n",
      "nowState: (2, 3), action: 0, nextState: (1, 3)\n",
      "nowState: (2, 3), action: 1, nextState: (2, 4)\n",
      "nowState: (2, 3), action: 2, nextState: (3, 3)\n",
      "nowState: (2, 3), action: 3, nextState: (2, 2)\n",
      "nowState: (2, 3), action: 4, nextState: (2, 3)\n",
      "nowState: (2, 4), action: 0, nextState: (1, 4)\n",
      "nowState: (2, 4), action: 1, nextState: (2, 5)\n",
      "nowState: (2, 4), action: 2, nextState: (3, 4)\n",
      "nowState: (2, 4), action: 3, nextState: (2, 3)\n",
      "nowState: (2, 4), action: 4, nextState: (2, 4)\n",
      "nowState: (3, 0), action: 0, nextState: (2, 0)\n",
      "nowState: (3, 0), action: 1, nextState: (3, 1)\n",
      "nowState: (3, 0), action: 2, nextState: (4, 0)\n",
      "nowState: (3, 0), action: 3, nextState: (3, -1)\n",
      "nowState: (3, 0), action: 4, nextState: (3, 0)\n",
      "nowState: (3, 1), action: 0, nextState: (2, 1)\n",
      "nowState: (3, 1), action: 1, nextState: (3, 2)\n",
      "nowState: (3, 1), action: 2, nextState: (4, 1)\n",
      "nowState: (3, 1), action: 3, nextState: (3, 0)\n",
      "nowState: (3, 1), action: 4, nextState: (3, 1)\n",
      "nowState: (3, 2), action: 0, nextState: (2, 2)\n",
      "nowState: (3, 2), action: 1, nextState: (3, 3)\n",
      "nowState: (3, 2), action: 2, nextState: (4, 2)\n",
      "nowState: (3, 2), action: 3, nextState: (3, 1)\n",
      "nowState: (3, 2), action: 4, nextState: (3, 2)\n",
      "nowState: (3, 3), action: 0, nextState: (2, 3)\n",
      "nowState: (3, 3), action: 1, nextState: (3, 4)\n",
      "nowState: (3, 3), action: 2, nextState: (4, 3)\n",
      "nowState: (3, 3), action: 3, nextState: (3, 2)\n",
      "nowState: (3, 3), action: 4, nextState: (3, 3)\n",
      "nowState: (3, 4), action: 0, nextState: (2, 4)\n",
      "nowState: (3, 4), action: 1, nextState: (3, 5)\n",
      "nowState: (3, 4), action: 2, nextState: (4, 4)\n",
      "nowState: (3, 4), action: 3, nextState: (3, 3)\n",
      "nowState: (3, 4), action: 4, nextState: (3, 4)\n",
      "nowState: (4, 0), action: 0, nextState: (3, 0)\n",
      "nowState: (4, 0), action: 1, nextState: (4, 1)\n",
      "nowState: (4, 0), action: 2, nextState: (5, 0)\n",
      "nowState: (4, 0), action: 3, nextState: (4, -1)\n",
      "nowState: (4, 0), action: 4, nextState: (4, 0)\n",
      "nowState: (4, 1), action: 0, nextState: (3, 1)\n",
      "nowState: (4, 1), action: 1, nextState: (4, 2)\n",
      "nowState: (4, 1), action: 2, nextState: (5, 1)\n",
      "nowState: (4, 1), action: 3, nextState: (4, 0)\n",
      "nowState: (4, 1), action: 4, nextState: (4, 1)\n",
      "nowState: (4, 2), action: 0, nextState: (3, 2)\n",
      "nowState: (4, 2), action: 1, nextState: (4, 3)\n",
      "nowState: (4, 2), action: 2, nextState: (5, 2)\n",
      "nowState: (4, 2), action: 3, nextState: (4, 1)\n",
      "nowState: (4, 2), action: 4, nextState: (4, 2)\n",
      "nowState: (4, 3), action: 0, nextState: (3, 3)\n",
      "nowState: (4, 3), action: 1, nextState: (4, 4)\n",
      "nowState: (4, 3), action: 2, nextState: (5, 3)\n",
      "nowState: (4, 3), action: 3, nextState: (4, 2)\n",
      "nowState: (4, 3), action: 4, nextState: (4, 3)\n",
      "nowState: (4, 4), action: 0, nextState: (3, 4)\n",
      "nowState: (4, 4), action: 1, nextState: (4, 5)\n",
      "nowState: (4, 4), action: 2, nextState: (5, 4)\n",
      "nowState: (4, 4), action: 3, nextState: (4, 3)\n",
      "nowState: (4, 4), action: 4, nextState: (4, 4)\n",
      "value: \n",
      " [6.51461602 7.24361602 6.51461602 5.85851602 5.26802602 7.24361602\n",
      " 8.05361602 7.24361602 6.51461602 5.85851602 8.05361602 8.95361602\n",
      " 8.05361602 7.24361602 6.51461602 8.95361602 9.95361602 8.95361602\n",
      " 8.05361602 7.24361602 9.95361602 9.95361602 9.95361602 8.95361602\n",
      " 8.05361602]\n",
      "➡️⬇️⬇️⬇️⬇️\n",
      "➡️⬇️⬇️⬇️⬇️\n",
      "⏩️⬇️⬇️⬇️⬇️\n",
      "➡️⬇️⬇️⬇️⬅️\n",
      "⏩️✅⬅️⬅️⏪\n",
      "iteration times: 1\n",
      "final value: \n",
      " [6.51461602 7.24361602 6.51461602 5.85851602 5.26802602 7.24361602\n",
      " 8.05361602 7.24361602 6.51461602 5.85851602 8.05361602 8.95361602\n",
      " 8.05361602 7.24361602 6.51461602 8.95361602 9.95361602 8.95361602\n",
      " 8.05361602 7.24361602 9.95361602 9.95361602 9.95361602 8.95361602\n",
      " 8.05361602]\n",
      "final policy: \n",
      " [1 2 2 2 2 1 2 2 2 2 1 2 2 2 2 1 2 2 2 3 1 4 3 3 3]\n",
      "➡️⬇️⬇️⬇️⬇️\n",
      "➡️⬇️⬇️⬇️⬇️\n",
      "⏩️⬇️⬇️⬇️⬇️\n",
      "➡️⬇️⬇️⬇️⬅️\n",
      "⏩️✅⬅️⬅️⏪\n"
     ]
    }
   ],
   "source": [
    "## policy iteration\n",
    "# 1. initialize value\n",
    "pre_value = value.copy() + 1\n",
    "\n",
    "grid_world.show()\n",
    "grid_world.show_policy_list(policy)\n",
    "\n",
    "# 2. value iteration\n",
    "## 设置截断条件，防止无限循环\n",
    "cut = 0\n",
    "cut_max = 1000\n",
    "## 设置阈值，当value的变化小于阈值时，停止迭代\n",
    "threshold = 1e-3\n",
    "\n",
    "while np.sum((pre_value - value)**2) > threshold and cut < cut_max:\n",
    "    print(\"Euclidean Distance:\",np.sum((pre_value-value)**2))\n",
    "    pre_value = value.copy()\n",
    "\n",
    "    \n",
    "    # 遍历每一个state\n",
    "    for i in range(rows * cols):\n",
    "        nowx = i // cols\n",
    "        nowy = i % cols\n",
    "        # 遍历每一个action\n",
    "        for j in range(5):\n",
    "            # 获取在当前state执行action j后的reward和下一个state\n",
    "            reward, next_state = grid_world.getScore(i, j)\n",
    "            # 更新qtable\n",
    "            qtable[i, j] = reward + gamma * value[next_state]\n",
    "    # 经过上面的循环，qtable已经更新完毕\n",
    "    # 首先获取policy\n",
    "    # 因为policy是按照贪心策略来选择的，所以只需要选择qtable中最大的值对应的action即可\n",
    "    policy = np.argmax(qtable, axis=1)\n",
    "    # 更新value\n",
    "    # value是根据qtable来更新的，每个state的value是qtable中最大的值\n",
    "    value = np.max(qtable, axis=1)\n",
    "\n",
    "    print(f'value: \\n {value}')\n",
    "    grid_world.show_policy_list(policy)\n",
    "\n",
    "    cut += 1\n",
    "print(f'iteration times: {cut}')    \n",
    "print(f'final value: \\n {value.reshape(rows, cols)}')\n",
    "print(f'final policy: \\n {policy}')\n",
    "grid_world.show_policy_list(policy)        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBP-TSTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
